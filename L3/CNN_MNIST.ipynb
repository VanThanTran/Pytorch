{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "O4BKowSQNk-N"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zR2GVbodNr2j"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # input 1 channel, output 32 channel, kernel size 3*3\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
        "        \n",
        "        self.fc1 = nn.Linear(14*14*32, 128)  # 14*14 from image dimension\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        # Flatten to vector to input the neural network\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tigjCTSEOLWF",
        "outputId": "4caea2d0-5483-438c-e79c-de8a28e0f277"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fc1): Linear(in_features=6272, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "net = Net()\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oYV12Vs8ONFB"
      },
      "outputs": [],
      "source": [
        "params = list(net.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(params))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9ZnoIsOg1s5",
        "outputId": "0c120076-dba2-4180-936a-137b4f1ec1c5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfkSg-5AOau4",
        "outputId": "f8308be7-4727-4234-9db5-8ba6d4139362"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "params[0].size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "728hNruUOict",
        "outputId": "dfe8b882-75b1-48b7-80cf-04d077ff6e7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "params[1].size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIZ5JXc9On98",
        "outputId": "27ee349e-8e31-434f-c8b9-69e2314db02a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True, True, True, True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "input = torch.randn(1, 1, 28, 28)\n",
        "out_call = net(input)\n",
        "out_forward = net.forward(input)\n",
        "\n",
        "out_call == out_forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRMN_W-3Ougm",
        "outputId": "12de1e66-e01e-4c77-df99-7471373db849"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inside Conv2d forward\n",
            "\n",
            "input:  <class 'tuple'> , len:  1\n",
            "input[0]:  <class 'torch.Tensor'> , shape:  torch.Size([1, 32, 28, 28])\n",
            "output:  <class 'torch.Tensor'> , len:  1 torch.Size([1, 32, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "net = Net()\n",
        "def print_info(self, input, output):\n",
        "    # input is a tuple of packed inputs\n",
        "    # output is a Tensor. output.data is the Tensor we are interested\n",
        "    print('Inside ' + self.__class__.__name__ + ' forward')\n",
        "    \n",
        "    print('')\n",
        "    print('input: ', type(input), ', len: ', len(input))\n",
        "    print('input[0]: ', type(input[0]), ', shape: ', input[0].shape)\n",
        "    print('output: ', type(output), ', len: ', len(output), output.data.shape)\n",
        "    \n",
        "\n",
        "net.conv2.register_forward_hook(print_info)\n",
        "\n",
        "out = net(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQ6j_pwR1VaA",
        "outputId": "382f84fd-fa95-4b00-a9ee-afdf12efc8cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inside Conv2d backward\n",
            "grad_input:  <class 'tuple'> , len:  3\n",
            "grad_output:  <class 'tuple'> , len:  1\n",
            "grad_output[0]:  <class 'torch.Tensor'> , size:  torch.Size([1, 32, 28, 28])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1025: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
            "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
          ]
        }
      ],
      "source": [
        "\n",
        "target = torch.tensor([3])\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "net = Net()\n",
        "def print_backward_info(self, grad_input, grad_output):\n",
        "    print('Inside ' + self.__class__.__name__ + ' backward')\n",
        "    print('grad_input: ', type(grad_input), ', len: ', len(grad_input))\n",
        "    print('grad_output: ', type(grad_output), ', len: ', len(grad_output))\n",
        "    print('grad_output[0]: ', type(grad_output[0]), ', size: ', grad_output[0].shape)\n",
        "\n",
        "\n",
        "net.conv1.register_backward_hook(print_backward_info)\n",
        "\n",
        "out = net(input)\n",
        "err = loss_fn(out, target)\n",
        "err.backward()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "trzs4mjiPGDO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CNN_MNIST.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}